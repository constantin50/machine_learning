Word embedding is the collective name for a set of language modeling and feature learning techniques 
in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers.

There several approches to it

## One Hot Encoding 

## TF-IDF

## Word2Vec
